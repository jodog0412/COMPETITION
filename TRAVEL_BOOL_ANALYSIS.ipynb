{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TRAVEL_BOOL_ANALYSIS.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN0HKsl4wMsUiYRff477zch",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jodog0412/DACON/blob/main/TRAVEL_BOOL_ANALYSIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "brUgcRpFxtsj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBidw9kXDlVl"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Colab/TRAVEL_PRODUCT_ANALYSIS\n",
        "!ls"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 데이터 로드"
      ],
      "metadata": {
        "id": "LxQOy7oBfywn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "train = pd.read_csv('dataset/train.csv')\n",
        "test = pd.read_csv('dataset/test.csv')\n",
        "sample_submission = pd.read_csv('dataset/sample_submission.csv')\n",
        "train.head()\n",
        "# train.isna().sum()"
      ],
      "metadata": {
        "id": "v7GRxH_XD_Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 데이터 결측치 처리"
      ],
      "metadata": {
        "id": "Qzc18cuuf7ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_na = train.copy()\n",
        "test_na = test.copy()\n",
        "\n",
        "# 0 으로 채우는 경우\n",
        "train_na.DurationOfPitch = train_na.DurationOfPitch.fillna(0)\n",
        "test_na.DurationOfPitch=test_na.DurationOfPitch.fillna(0)\n",
        "\n",
        "\n",
        "# mean 값으로 채우는 경우\n",
        "mean_cols = ['Age',\n",
        "             'NumberOfFollowups',\n",
        "             'PreferredPropertyStar',\n",
        "             'NumberOfTrips',\n",
        "             'NumberOfChildrenVisiting',\n",
        "             'MonthlyIncome']\n",
        "             \n",
        "for col in mean_cols:\n",
        "    train_na[col] = train_na[col].fillna(train[col].mean())\n",
        "    test_na[col] = test_na[col].fillna(test[col].mean())\n",
        "\n",
        "# \"Unknown\"으로 채우는 경우\n",
        "train_na.TypeofContact = train_na.TypeofContact.fillna(\"Unknown\")\n",
        "test_na.TypeofContact = test_na.TypeofContact.fillna(\"Unknown\")"
      ],
      "metadata": {
        "id": "zTBjLGukevwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. 문자열 변수 전처리"
      ],
      "metadata": {
        "id": "fEZqMds1gPEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "object_columns = train.columns[train.dtypes == 'object']\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "train_enc = train_na.copy()\n",
        "test_enc=test_na.copy()\n",
        "for o_col in object_columns:\n",
        "    encoder = LabelEncoder()\n",
        "    encoder.fit(train_enc[o_col])\n",
        "    train_enc[o_col] = encoder.transform(train_enc[o_col])\n",
        "    test_enc[o_col] = encoder.transform(test_enc[o_col])\n",
        "\n",
        "train_enc.info()\n",
        "train_enc.describe(include=\"number\")\n",
        "# train_enc[\"MonthlyIncome\"].hist(bins=100)"
      ],
      "metadata": {
        "id": "fw-f_CB4EZ1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. 스케일링"
      ],
      "metadata": {
        "id": "odoHWUktgv5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "train_scale = train_enc.copy()\n",
        "test_scale=test_enc.copy()\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(train_scale[['Age',\n",
        "                        'DurationOfPitch',\n",
        "                        'MonthlyIncome']])\n",
        "train_scale[['Age','DurationOfPitch','MonthlyIncome']] = scaler.transform(train_scale[['Age', \n",
        "                                                                                       'DurationOfPitch', \n",
        "                                                                                       'MonthlyIncome']])\n",
        "test_scale[['Age', 'DurationOfPitch', 'MonthlyIncome']] = scaler.transform(test_scale[['Age',\n",
        "                                                                                       'DurationOfPitch',\n",
        "                                                                                       'MonthlyIncome']])\n",
        "# 결과를 확인합니다.\n",
        "train_scale.info()"
      ],
      "metadata": {
        "id": "cyUFHdbLgz5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. 머신러닝"
      ],
      "metadata": {
        "id": "yzOEXFSnikMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) RandomForest"
      ],
      "metadata": {
        "id": "i8hPqmxSSR0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "x_train = train_scale.drop(columns=['id','ProdTaken'])\n",
        "y_train = train_scale[['ProdTaken']]\n",
        "x_test = test_scale.drop(columns=['id'])\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "model.fit(x_train,y_train)\n",
        "prediction = model.predict(x_test)"
      ],
      "metadata": {
        "id": "Rg7MfQlPSZut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. DEEP LEARNING"
      ],
      "metadata": {
        "id": "e39Ui0EtZl96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "x_train = train_scale.drop(columns=['id','ProdTaken'])\n",
        "y_train = train_scale[['ProdTaken']]\n",
        "x_test = test_scale.drop(columns=['id'])\n",
        "\n",
        "config = {\n",
        "    'EPOCHS': 10000, #에포크\n",
        "    'LEARNING_RATE':2e-2, #학습률\n",
        "    'BATCH_SIZE':12, #배치사이즈\n",
        "    'SEED':41, #시드\n",
        "}\n",
        "X=torch.tensor(x_train.values)\n",
        "Y=torch.tensor(y_train.values)\n",
        "model = nn.Sequential(\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(18, 32),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(32, 64),\n",
        "    nn.LeakyReLU(),\n",
        "    nn.Linear(64, 1),\n",
        ")\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=5e-3)\n",
        "loss_fn = F.binary_cross_entropy_with_logits\n",
        "losses=[]\n",
        "accur=[]\n",
        "Y_pred=[]\n",
        "for epoch in range(config['EPOCHS']):\n",
        "    optimizer.zero_grad() \n",
        "    y_pred = model(X.float())  \n",
        "    acc = (y_pred.detach().numpy().round() == y_train.values).mean()\n",
        "    loss = loss_fn(y_pred, Y.float())\n",
        "    loss.backward()  \n",
        "    optimizer.step()  \n",
        "    losses.append(loss.item())\n",
        "    accur.append(acc.item())\n",
        "    Y_pred.append(y_pred)\n",
        "plt.plot(losses)"
      ],
      "metadata": {
        "id": "_uDZIgrBWUJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "Y_pred=model(X.float())>torch.tensor([0.5])\n",
        "cf = confusion_matrix(y_train, Y_pred.detach().numpy())\n",
        "print(cf)\n",
        "acc=(cf[0][0]+cf[1][1])/(cf[0][0]+cf[0][1]+cf[1][0]+cf[1][1])\n",
        "print(acc)"
      ],
      "metadata": {
        "id": "-yd8a1v0Y2Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0t5Qr0OAXki8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XYwHYqbfpk4b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_submission['ProdTaken'] = prediction\n",
        "sample_submission.head()\n",
        "sample_submission.to_csv('submission.csv',index = False)"
      ],
      "metadata": {
        "id": "Gw2OyAmZjU4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0P3ut6TEthFW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}